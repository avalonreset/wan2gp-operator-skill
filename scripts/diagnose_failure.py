#!/usr/bin/env python3
"""
Diagnose common Wan2GP failures from a log file.

Usage:
  python scripts/diagnose_failure.py --log-file path/to/run.log
"""

from __future__ import annotations

import argparse
import json
import re
import sys
from pathlib import Path
from typing import Any


ISSUE_DEFINITIONS = [
    {
        "id": "cuda_oom",
        "severity": "critical",
        "patterns": [
            r"cuda out of memory",
            r"cudnn_status_alloc_failed",
            r"outofmemoryerror",
        ],
        "why": "GPU memory pressure exceeded available VRAM.",
        "actions": [
            "Retry with: --model-preset t2v-1-3B --attention sdpa --profile 4",
            "Lower frames/steps/resolution in your queue/settings file.",
            "Disable heavy options first (for example --compile on unstable setups).",
        ],
    },
    {
        "id": "triton_or_sage_backend",
        "severity": "high",
        "patterns": [
            r"no module named 'triton'",
            r"triton.*(not found|importerror)",
            r"sageattention",
            r"flash attention.*(failed|error|not available)",
        ],
        "why": "Advanced attention backend dependencies are missing or incompatible.",
        "actions": [
            "Fallback command: --attention sdpa --profile 4",
            "Only re-enable --attention sage/sage2 after Triton/SageAttention is confirmed.",
        ],
    },
    {
        "id": "queue_input_invalid",
        "severity": "high",
        "patterns": [
            r"file not found",
            r"no such file or directory",
            r"invalid queue",
            r"unsupported file type",
        ],
        "why": "Queue/settings file path is wrong or format is invalid.",
        "actions": [
            "Confirm the process file exists and has .zip or .json extension.",
            "If using .json, verify referenced media files exist at expected paths.",
            "Run plan script again to verify path resolution.",
        ],
    },
    {
        "id": "port_conflict",
        "severity": "medium",
        "patterns": [
            r"port .* already in use",
            r"address already in use",
            r"failed to bind",
        ],
        "why": "The target server port is already occupied.",
        "actions": [
            "Use a different port, for example: --extra-arg --server-port --extra-arg 7861",
            "Stop the process currently using the conflicting port.",
        ],
    },
    {
        "id": "missing_cuda_runtime",
        "severity": "high",
        "patterns": [
            r"torch\.cuda\.is_available\(\).*false",
            r"cuda driver",
            r"no cuda",
            r"cuda.*not available",
        ],
        "why": "CUDA runtime/driver mismatch or unavailable GPU runtime.",
        "actions": [
            "Validate GPU runtime first (driver + torch build).",
            "Start with CPU-safe diagnostics and install matching CUDA PyTorch build.",
        ],
    },
    {
        "id": "missing_python_dependency",
        "severity": "high",
        "patterns": [
            r"no module named 'torch'",
            r"no module named \"torch\"",
            r"modulenotfounderror: no module named",
            r"importerror: no module named",
        ],
        "why": "Wan2GP Python environment is missing required packages.",
        "actions": [
            "Activate the Wan2GP environment, then run: pip install -r requirements.txt",
            "Install the matching PyTorch build for your CUDA/ROCm stack before retrying.",
            "Re-run dry-run first after dependencies are installed.",
        ],
    },
]

SEVERITY_RANK = {"critical": 4, "high": 3, "medium": 2, "low": 1}


def parse_args() -> argparse.Namespace:
    """Parse CLI args."""
    parser = argparse.ArgumentParser(description="Diagnose Wan2GP run failures")
    parser.add_argument("--log-file", help="Path to log file generated by run_headless.py")
    parser.add_argument("--text", help="Raw log text to analyze")
    return parser.parse_args()


def load_text(args: argparse.Namespace) -> str:
    """Load text from --text, --log-file, or stdin."""
    if args.text:
        return args.text
    if args.log_file:
        path = Path(args.log_file).expanduser().resolve()
        if not path.exists():
            raise FileNotFoundError(f"Log file not found: {path}")
        return path.read_text(encoding="utf-8", errors="replace")

    if not sys.stdin.isatty():
        return sys.stdin.read()
    raise ValueError("Provide --log-file, --text, or piped stdin input.")


def detect_issues(log_text: str) -> list[dict[str, Any]]:
    """Return matching issue reports."""
    findings: list[dict[str, Any]] = []
    for issue in ISSUE_DEFINITIONS:
        matched_snippets: list[str] = []
        for pattern in issue["patterns"]:
            matches = re.findall(pattern, log_text, flags=re.IGNORECASE)
            for match in matches:
                snippet = match if isinstance(match, str) else " ".join(match)
                if snippet and snippet not in matched_snippets:
                    matched_snippets.append(snippet)
        if matched_snippets:
            findings.append(
                {
                    "id": issue["id"],
                    "severity": issue["severity"],
                    "why": issue["why"],
                    "actions": issue["actions"],
                    "matched_snippets": matched_snippets[:5],
                }
            )

    findings.sort(key=lambda item: SEVERITY_RANK.get(item["severity"], 0), reverse=True)
    return findings


def main() -> int:
    """CLI entrypoint."""
    args = parse_args()
    try:
        log_text = load_text(args)
        issues = detect_issues(log_text)
        report = {
            "status": "success",
            "issues_found": len(issues),
            "issues": issues,
            "summary": (
                "No known failure signatures detected. Review full logs for stack traces."
                if not issues
                else "Apply the highest-severity action first, then retest."
            ),
        }
        print(json.dumps(report, indent=2))
        return 0
    except Exception as exc:
        print(
            json.dumps(
                {
                    "status": "error",
                    "error": str(exc),
                },
                indent=2,
            ),
            file=sys.stderr,
        )
        return 1


if __name__ == "__main__":
    sys.exit(main())
